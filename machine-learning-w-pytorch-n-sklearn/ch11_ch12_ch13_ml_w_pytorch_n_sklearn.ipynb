{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning with PyTorch and Sklearn - Raschka, Liu, and Mirjalili</center>\n",
    "## <center>Chapters 11, 12, and 13</center>\n",
    "### <center>Implementing a Multilayer Artificial Neural Network from Scratch</center>\n",
    "### <center>and</center>\n",
    "### <center>Parallelizing Neural Network Training with PyTorch</center>\n",
    "### <center>and</center>\n",
    "### <center>Going Deeper – The Mechanics of PyTorch</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "\n",
    "> The trick of reverse mode is that we traverse the chain rule from right to left. We multiply a matrix by a vector, which yields another vector that is multiplied by the next matrix, and so on. Matrix-vector multiplication is computationally much cheaper than matrix-matrix multiplication, which is why backpropagation is one of the most popular algorithms used in NN training.\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "- Importante diferenciar o _forward pass_ que ele fala do _backward pass_. A definição do livro de forward propagation parece um pouco imprecisa. Escreva aqui em termo de _forward pass_ e _backward pass_.\n",
    "\n",
    "- _Feedforward artificial NN_. Definir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "AI history:\n",
    "\n",
    "> [AI winters](https://en.wikipedia.org/wiki/AI_winter)\n",
    "\n",
    "Additional resources on backpropagation:\n",
    "\n",
    "> [Who Invented Backpropagation?](http://people.idsia.ch/~juergen/who-invented-backpropagation.html)\n",
    "\n",
    "> Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. nature, 323(6088), 533-536.\n",
    "\n",
    "> Chapter 6, Deep Feedforward Networks, Deep Learning, by I. Goodfellow, Y. Bengio, and A. Courville, MIT Press, 2016 (manuscripts freely accessible at http://www.deeplearningbook.org).\n",
    "\n",
    "> Pattern Recognition and Machine Learning, by C. M. Bishop, Springer New York, 2006.\n",
    "\n",
    "The MNSIT dataset:\n",
    "\n",
    "> LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\n",
    "\n",
    "Adding skip-connections, which are the main contribution of residual NNs:\n",
    "\n",
    "> He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).\n",
    "\n",
    "Using learning rate schedulers that change the learning rate during training:\n",
    "\n",
    "> Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In 2017 IEEE winter conference on applications of computer vision (WACV) (pp. 464-472). IEEE.\n",
    "\n",
    "Attaching loss functions to earlier layers in the networks as it’s being done in the popular ``Inception v3`` architecture:\n",
    "\n",
    "> Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2016). Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2818-2826).\n",
    "\n",
    "Automatic differentiation:\n",
    "\n",
    "> Baydin, A. G., & Pearlmutter, B. A. (2014). Automatic differentiation of algorithms for machine learning. arXiv preprint arXiv:1404.7456.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cuda.FloatTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5290, 0.8148, 0.2979, 0.2081, 0.8574],\n",
      "        [0.6506, 0.9768, 0.6655, 0.3058, 0.8328],\n",
      "        [0.9598, 0.8347, 0.1182, 0.8505, 0.7721],\n",
      "        [0.7770, 0.5142, 0.3316, 0.3090, 0.8752]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5290, 0.6506, 0.9598, 0.7770],\n",
      "        [0.8148, 0.9768, 0.8347, 0.5142],\n",
      "        [0.2979, 0.6655, 0.1182, 0.3316],\n",
      "        [0.2081, 0.3058, 0.8505, 0.3090],\n",
      "        [0.8574, 0.8328, 0.7721, 0.8752]])\n",
      "tensor([[0.5290, 0.8148],\n",
      "        [0.2979, 0.2081],\n",
      "        [0.8574, 0.6506],\n",
      "        [0.9768, 0.6655],\n",
      "        [0.3058, 0.8328],\n",
      "        [0.9598, 0.8347],\n",
      "        [0.1182, 0.8505],\n",
      "        [0.7721, 0.7770],\n",
      "        [0.5142, 0.3316],\n",
      "        [0.3090, 0.8752]])\n"
     ]
    }
   ],
   "source": [
    "# Transposing a tensor\n",
    "print(tensor.T)\n",
    "\n",
    "# Reshaping\n",
    "# The reshaped tensor must have the same number of elements as the original\n",
    "print(tensor.reshape(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]]]])\n",
      "tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing\n",
    "print(torch.zeros(1, 2, 1, 4, 1))\n",
    "print(torch.zeros(1, 2, 1, 4, 1).squeeze(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat-01.jpg',\n",
       " 'cat-02.jpg',\n",
       " 'cat-03.jpg',\n",
       " 'dog-01.jpg',\n",
       " 'dog-02.jpg',\n",
       " 'dog-03.jpg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = os.listdir(\"input/ch12/\")\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementar projeto com o MNSIT usando PyTorch. Procurar se há formas de fazer isso sem usar as definições de classe que ele usou no livro. Fazer tudo usando k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
